{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aab5a41-c6b5-410b-89d2-4ad3048001cb",
   "metadata": {},
   "source": [
    "### 聚类评估指标实现及使用示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf256d3f-a82b-4f97-a3ca-62ccec025602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "轮廓系数 by sklearn: 0.5528190123564095\n",
      "轮廓系数 by ours: 0.5528190123564101\n",
      "方差比 by sklearn: 561.5937320156642\n",
      "方差比 by ours: 561.5937320156642\n",
      "db_score by sklearn: 0.6619715465007465\n",
      "db_score by ours: 0.6619715465007465\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "\n",
    "def get_silhouette_coefficient(X, labels):\n",
    "    \"\"\"\n",
    "    轮廓系数计算\n",
    "    :param X: shape: [n_samples,n_features]\n",
    "    :param labels: shape: [n_samples,]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    n_clusters = np.unique(labels).shape[0]\n",
    "    s = []\n",
    "    for k in range(n_clusters):  # 遍历每一个簇\n",
    "        index = (labels == k)  # 取对应簇所有样本的索引\n",
    "        x_in_cluster = X[index]  # 去对应簇中的所有样本\n",
    "        for sample in x_in_cluster:  # 计算每个样本的轮廓系数\n",
    "            a = ((sample - x_in_cluster) ** 2).sum(axis=1)\n",
    "            a = np.sqrt(a).sum() / (len(a) - 1)  # 去掉当前样本点与当前样本点的组合计数\n",
    "            nearest_cluster_id = None\n",
    "            min_dist2 = np.inf\n",
    "            for c in range(n_clusters):  # 寻找距离当前样本点最近的簇\n",
    "                if k == c:\n",
    "                    continue\n",
    "                centroid = X[labels == c].mean(axis=0)\n",
    "                dist2 = ((sample - centroid) ** 2).sum()\n",
    "                if dist2 < min_dist2:\n",
    "                    nearest_cluster_id = c\n",
    "                    min_dist2 = dist2\n",
    "            x_nearest_cluster = X[labels == nearest_cluster_id]\n",
    "            b = ((sample - x_nearest_cluster) ** 2).sum(axis=1)\n",
    "            b = np.sqrt(b).mean()\n",
    "            s.append((b - a) / np.max([a, b]))\n",
    "    return np.mean(s)\n",
    "\n",
    "\n",
    "def get_calinski_harabasz(X, labels):\n",
    "    n_samples = X.shape[0]\n",
    "    n_clusters = np.unique(labels).shape[0]\n",
    "    betw_disp = 0.  # 所有的簇间距离和\n",
    "    within_disp = 0.  # 所有的簇内距离和\n",
    "    global_centroid = np.mean(X, axis=0)  # 全局簇中心\n",
    "    for k in range(n_clusters):  # 遍历每一个簇\n",
    "        x_in_cluster = X[labels == k]  # 取当前簇中的所有样本\n",
    "        centroid = np.mean(x_in_cluster, axis=0)  # 计算当前簇的簇中心\n",
    "        # 计算所有样本点到其对应簇中心的距离和（平方）\n",
    "        within_disp += np.sum((x_in_cluster - centroid) ** 2)\n",
    "        # 计算每个簇中心到全局簇中心的距离和（平方）* 当前簇的样本数\n",
    "        betw_disp += len(x_in_cluster) * np.sum((centroid - global_centroid) ** 2)\n",
    "\n",
    "    return (1. if within_disp == 0. else\n",
    "            betw_disp * (n_samples - n_clusters) /\n",
    "            (within_disp * (n_clusters - 1.)))\n",
    "\n",
    "\n",
    "def get_davies_bouldin(X, labels):\n",
    "    n_clusters = np.unique(labels).shape[0]\n",
    "    centroids = np.zeros((n_clusters, len(X[0])), dtype=float)\n",
    "    s_i = np.zeros(n_clusters)\n",
    "    for k in range(n_clusters):  # 遍历每一个簇\n",
    "        x_in_cluster = X[labels == k]  # 取当前簇中的所有样本\n",
    "        centroids[k] = np.mean(x_in_cluster, axis=0)  # 计算当前簇的簇中心\n",
    "        s_i[k] = pairwise_distances(x_in_cluster, [centroids[k]]).mean()  #\n",
    "    centroid_distances = pairwise_distances(centroids)  # [K,K]\n",
    "    combined_s_i_j = s_i[:, None] + s_i  # [K,k]\n",
    "    centroid_distances[centroid_distances == 0] = np.inf\n",
    "    scores = np.max(combined_s_i_j / centroid_distances, axis=1)\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "def test_silhouette_score():\n",
    "    x, y = load_iris(return_X_y=True)\n",
    "    model = KMeans(n_clusters=3)\n",
    "    model.fit(x)\n",
    "    y_pred = model.predict(x)\n",
    "    print(f\"轮廓系数 by sklearn: {silhouette_score(x, y_pred)}\")\n",
    "    print(f\"轮廓系数 by ours: {get_silhouette_coefficient(x, y_pred)}\")\n",
    "\n",
    "\n",
    "def test_calinski_harabasz_score():\n",
    "    x, y = load_iris(return_X_y=True)\n",
    "    model = KMeans(n_clusters=3)\n",
    "    model.fit(x)\n",
    "    y_pred = model.predict(x)\n",
    "    print(f\"方差比 by sklearn: {calinski_harabasz_score(x, y_pred)}\")\n",
    "    print(f\"方差比 by ours: {get_calinski_harabasz(x, y_pred)}\")\n",
    "\n",
    "\n",
    "def test_davies_bouldin_score():\n",
    "    x, y = load_iris(return_X_y=True)\n",
    "    model = KMeans(n_clusters=3)\n",
    "    model.fit(x)\n",
    "    y_pred = model.predict(x)\n",
    "    print(f\"db_score by sklearn: {davies_bouldin_score(x, y_pred)}\")\n",
    "    print(f\"db_score by ours: {get_davies_bouldin(x, y_pred)}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_silhouette_score()\n",
    "    test_calinski_harabasz_score()\n",
    "    test_davies_bouldin_score()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
