"""
文件名: AllBooKCode/Chapter08/C24_example_gradient_boost_cla.py
创建时间: 2022/11/6 8:47 上午 星期日
作 者: @空字符
公众号: @月来客栈
知 乎: @月来客栈 https://www.zhihu.com/people/the_lastest
"""

from C22_manual_gradient_boost_cla import negative_gradient
from C22_manual_gradient_boost_cla import objective_function
import numpy as np


def example():
    y = np.array([2, 1, 2, 0, 0])
    K = 3
    M = 3
    learning_rate = 0.5
    Y = np.zeros((y.shape[0], K), dtype=np.float64)
    for k in range(K):
        Y[:, k] = y == k
    print(f"原始标签的one-hot编码结果为:\n {Y}")
    raw_predictions = np.array([[0, 0.1, 0.3],
                                [0.2, 0.2, 0.1],
                                [0.3, 0.2, 0.1],
                                [0, 0, 0.4],
                                [0, 0.1, 0]])  # [n_samples,n_classes]
    print(f"初始化所有样本的预测概率为:\n {raw_predictions}")
    print(f"此时的损失值为: {objective_function(y, raw_predictions, K)}")
    for m in range(M):
        for k in range(K):
            grad = negative_gradient(y, raw_predictions, k)
            print(f"第{m + 1}次提升时类别{k}下所有样本对应的负梯度为{grad}")
            raw_predictions[:, k] += learning_rate * grad  # 梯度下降更新预测概率
        print(f"第{m + 1}次提升后的损失值为: {objective_function(y, raw_predictions, K)}")
        print(f"第{m + 1}次提升后的预测概率为:\n {raw_predictions}")
        print(f"第{m + 1}次提升后的预测值为: {np.argmax(raw_predictions, 1)}")


if __name__ == '__main__':
    example()
    # 原始标签的one-hot编码结果为:
    #  [[0. 0. 1.]
    #  [0. 1. 0.]
    #  [0. 0. 1.]
    #  [1. 0. 0.]
    #  [1. 0. 0.]]
    # 初始化所有样本的预测概率为:
    #  [[0.  0.1 0.3]
    #  [0.2 0.2 0.1]
    #  [0.3 0.2 0.1]
    #  [0.  0.  0.4]
    #  [0.  0.1 0. ]]
    # 此时的损失值为: 1.1183289054183767
    # 第1次提升时类别0下所有样本对应的负梯度为[-0.28943311 -0.34425335 -0.3671654   0.71361678  0.67795654]
    # 第1次提升时类别1下所有样本对应的负梯度为[-0.33285301  0.63592807 -0.35402586 -0.25506386 -0.31498163]
    # 第1次提升时类别2下所有样本对应的负梯度为[ 0.57159009 -0.28991565  0.66014493 -0.39249744 -0.2987176 ]
    # 第1次提升后的损失值为: 0.8163054134151766
    # 第1次提升后的预测概率为:
    #  [[-0.14471656 -0.0664265   0.58579504]
    #  [ 0.02787333  0.51796403 -0.04495783]
    #  [ 0.1164173   0.02298707  0.43007246]
    #  [ 0.35680839 -0.12753193  0.20375128]
    #  [ 0.33897827 -0.05749081 -0.1493588 ]]
    # 第1次提升后的预测值为: [2 1 2 0 0]
    # 第2次提升时类别0下所有样本对应的负梯度为[-0.24052461 -0.28072365 -0.30495063  0.59582638  0.56261917]
    # 第2次提升时类别1下所有样本对应的负梯度为[-0.26739985  0.52423847 -0.29026762 -0.21838124 -0.25761752]
    # 第2次提升时类别2下所有样本对应的负梯度为[ 0.46887159 -0.23715376  0.54609337 -0.31118079 -0.24255734]
    # 第2次提升后的损失值为: 0.6112225347181921
    # 第2次提升后的预测概率为:
    #  [[-0.26497886 -0.20012643  0.82023084]
    #  [-0.1124885   0.78008327 -0.16353471]
    #  [-0.03605802 -0.12214674  0.70311915]
    #  [ 0.65472158 -0.23672255  0.04816089]
    #  [ 0.62028785 -0.18629957 -0.27063747]]
    # 第2次提升后的预测值为: [2 1 2 0 0]
    # 第3次提升时类别0下所有样本对应的负梯度为[-0.19892335 -0.22770562 -0.24926936  0.48856586  0.46139689]
    # 第3次提升时类别1下所有样本对应的负梯度为[-0.21632561  0.43011522 -0.23558929 -0.18372075 -0.21094068]
    # 第3次提升时类别2下所有样本对应的负梯度为[ 0.38626147 -0.19512818  0.44781469 -0.24827984 -0.198062  ]
    # 第3次提升后的损失值为: 0.4732878324433384
    # 第3次提升后的预测概率为:
    #  [[-0.36444053 -0.30828923  1.01336157]
    #  [-0.22634131  0.99514087 -0.2610988 ]
    #  [-0.1606927  -0.23994138  0.9270265 ]
    #  [ 0.89900451 -0.32858292 -0.07597903]
    #  [ 0.8509863  -0.29176992 -0.36966847]]
    # 第3次提升后的预测值为: [2 1 2 0 0]
